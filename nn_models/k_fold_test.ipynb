{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c35d1cc",
   "metadata": {},
   "source": [
    "# Greenhouse Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195db0c9",
   "metadata": {},
   "source": [
    "## Import dependencies and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77453a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0186ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prop. funcs and models\n",
    "\n",
    "from data_funcs import k_fold_data_validation\n",
    "from train_funcs import train_network, test_autoreg\n",
    "from networks import feedForwardNeuralNetwork, recurrentNeuralNetwork\n",
    "from opts import AdaGrad, RMSProp, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a564526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external models\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ace44",
   "metadata": {},
   "source": [
    "## Create data for specific fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594fb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant paths\n",
    "home_path = os.path.dirname(os.getcwd())\n",
    "data_path = home_path + '\\\\data\\\\'\n",
    "results_path = home_path + '\\\\nn_models\\\\results\\\\'\n",
    "\n",
    "# get merged data\n",
    "data = pd.read_csv(\n",
    "    data_path + 'data_processed.csv',\n",
    "    header=[0, 1],\n",
    "    index_col=[0, 1, 2, 3, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be39f67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TA01_GT10X_GM10X', 'DC_GT101_GM101', 'DC_GT102_GM102',\n",
       "       'DC_GT103_GM103', 'DC_GT104_GM104', 'DC_GT401_GM401',\n",
       "       'TA01_GT401_GM401', 'TA02_GT401_GM401', 'outdoor', 'DC_GT101_GM101_abs',\n",
       "       'DC_GT102_GM102_abs', 'DC_GT103_GM103_abs', 'DC_GT104_GM104_abs',\n",
       "       'TA01_GT10X_GM10X_abs', 'TA01_GT401_GM401_abs', 'TA02_GT401_GM401_abs',\n",
       "       'outdoor_abs', 'TA01_GT401_GM401_rel', 'TA02_GT401_GM401_rel',\n",
       "       'outdoor_rel', 'TA01_GT401_GM401_scaled', 'TA02_GT401_GM401_scaled',\n",
       "       'outdoor_scaled', 'TA_inflow', 'TA_inflow_out'],\n",
       "      dtype='object', name='sensor_ID')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.humidity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa55a697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define data specs\n",
    "k_frac = 0.05\n",
    "m = 5\n",
    "t_steps = 1\n",
    "n_steps = 6\n",
    "\n",
    "# Define cols to use\n",
    "cols = [\n",
    "    ('temperatures', 'TA01_GT10X_GM10X'),\n",
    "    ('temperatures', 'TA01_GT401_GM401'),\n",
    "    ('temperatures', 'DC_GT301_damped'),\n",
    "    ('sun', 'gsi'),\n",
    "    ('power', 'phase'),\n",
    "    ('time', 'minofday'),\n",
    "    ('humidity', 'TA01_GT10X_GM10X_abs'),\n",
    "    ('humidity', 'TA01_GT401_GM401_abs'),\n",
    "    ('humidity', 'outdoor_abs'),\n",
    "    ('temperatures', 'TA01_GT401_GM401_scaled'),\n",
    "    ('temperatures', 'DC_GT301_damped_scaled'),\n",
    "#     ('state', 'TA01_output'),\n",
    "#     ('state', 'TA02_output')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187819d",
   "metadata": {},
   "source": [
    "## K-fold CV - Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc61265",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7778e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparams\n",
    "k1 = 10\n",
    "k2 = 1\n",
    "lambd = 0.01\n",
    "sigma = 1.0\n",
    "seed = 1\n",
    "\n",
    "# more params\n",
    "n_epochs = 50\n",
    "n_batch = 128\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40772677",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_idx in range(11, 20):\n",
    "    train_tup, test_tup, val_tup, col_params = k_fold_data_validation(\n",
    "        data=data.copy(), \n",
    "        k_idx=k_idx, \n",
    "        k_frac=k_frac, \n",
    "        m=m, \n",
    "        cols=cols, \n",
    "        t_steps=t_steps, \n",
    "        n_steps=n_steps,\n",
    "        setpoint=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # extract tuples\n",
    "    (sequences_train, targets_train, temps_train, temps_t_train, _) = train_tup\n",
    "    (sequences_test, targets_test, temps_test, temps_t_test, sequences_masked, _) = test_tup\n",
    "    (sequences_val, targets_val, temps_val, temps_t_val, _) = val_tup\n",
    "    \n",
    "    ### ----- FEED-FORWARD NN -----\n",
    "    # define network\n",
    "    model_name = 'FFNN_v{}_k{}'.format(version, k_idx)\n",
    "    units=[32, 32, 32]\n",
    "    model = feedForwardNeuralNetwork(\n",
    "        k1=k1,\n",
    "        k2=k2,\n",
    "        m=units,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # define optimizer\n",
    "    adam = Adam(\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        eps=1e-8,\n",
    "        weights=model.weights,\n",
    "    )\n",
    "    \n",
    "    # set optimizer\n",
    "    model.optimizer = adam\n",
    "    \n",
    "    # train model\n",
    "    results = train_network(\n",
    "        model=model,\n",
    "        train_data=(sequences_train[:, -2, :], temps_t_train, targets_train),\n",
    "        val_data=(sequences_val[:, -2, :], temps_t_val, targets_val),\n",
    "        seed=seed,\n",
    "        n_epochs=n_epochs,\n",
    "        n_batch=n_batch,\n",
    "        lambd=lambd,\n",
    "        sigma=sigma,\n",
    "        lr=lr,\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    \n",
    "    # get autoregressive test predictions\n",
    "    test_preds, test_encodings = test_autoreg(\n",
    "        model,\n",
    "        sequences_masked[:, -2, :],\n",
    "        temps_t_test,\n",
    "        targets_test,\n",
    "        t_steps\n",
    "    )\n",
    "    \n",
    "    results['test_preds'] = test_preds\n",
    "    results['test_encodings'] = test_encodings\n",
    "    \n",
    "    # save results\n",
    "    save_path = results_path + 'ffnn\\\\' + model_name + '.pickle'\n",
    "    with open(save_path, 'wb') as fo:\n",
    "        pickle.dump(results, fo)\n",
    "    \n",
    "    # clear output\n",
    "    clear_output()\n",
    "    \n",
    "    \n",
    "    ### ----- RECURRENT NN -----\n",
    "    # define network\n",
    "    model_name = 'RNN_v{}_k{}'.format(version, k_idx)\n",
    "    units = 32\n",
    "    model = recurrentNeuralNetwork(\n",
    "        k1=k1,\n",
    "        k2=k2,\n",
    "        m=units,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # define optimizer\n",
    "    adam = Adam(\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        eps=1e-8,\n",
    "        weights=model.weights,\n",
    "    )\n",
    "    \n",
    "    # set optimizer\n",
    "    model.optimizer = adam\n",
    "    \n",
    "    # train model\n",
    "    results = train_network(\n",
    "        model=model,\n",
    "        train_data=(sequences_train, temps_t_train, targets_train),\n",
    "        val_data=(sequences_val, temps_t_val, targets_val),\n",
    "        seed=seed,\n",
    "        n_epochs=n_epochs,\n",
    "        n_batch=n_batch,\n",
    "        lambd=lambd,\n",
    "        sigma=sigma,\n",
    "        lr=lr,\n",
    "        optimizer='adam'\n",
    "    )\n",
    " \n",
    "    # get autoregressive test predictions\n",
    "    test_preds, test_encodings = test_autoreg(\n",
    "        model,\n",
    "        sequences_masked,\n",
    "        temps_t_test,\n",
    "        targets_test,\n",
    "        t_steps\n",
    "    )\n",
    "    \n",
    "    results['test_preds'] = test_preds\n",
    "    results['test_encodings'] = test_encodings\n",
    "\n",
    "    # save results\n",
    "    save_path = results_path + 'rnn\\\\' + model_name + '.pickle'\n",
    "    with open(save_path, 'wb') as fo:\n",
    "        pickle.dump(results, fo)\n",
    "\n",
    "    # clear output\n",
    "    clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af03e42",
   "metadata": {},
   "source": [
    "## K-fold CV - other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fad0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k_idx in range(20):\n",
    "#     train_tup, test_tup, val_tup, col_params = k_fold_data_validation(\n",
    "#         data=data.copy(), \n",
    "#         k_idx=k_idx, \n",
    "#         k_frac=k_frac, \n",
    "#         m=m, \n",
    "#         cols=cols, \n",
    "#         t_steps=t_steps, \n",
    "#         n_steps=n_steps,\n",
    "#         setpoint=True,\n",
    "#         shuffle=False\n",
    "#     )\n",
    "    \n",
    "#     # extract tuples\n",
    "#     (sequences_train, targets_train, temps_train, temps_t_train, _) = train_tup\n",
    "#     (sequences_test, targets_test, temps_test, temps_t_test, sequences_masked, _) = test_tup\n",
    "#     (sequences_val, targets_val, temps_val, temps_t_val, _) = val_tup\n",
    "\n",
    "#     ### TRAIN ARIMA\n",
    "#     clear_output()\n",
    "#     print('TRAINING ARIMA, k_idx: {}'.format(k_idx))\n",
    "    \n",
    "#     # get model name\n",
    "#     model_name = 'arima_v{}_k{}'.format(version, k_idx)\n",
    "    \n",
    "#     # get endogenous and exogenous regressors\n",
    "#     endog_train = temps_t_train.tolist()\n",
    "#     exog_train = [np.array(seq) for seq in sequences_train[:, -2, :].tolist()]\n",
    "# #     exog_train = [np.array(seq).mean(axis=0) for seq in sequences_train[:, -t_steps:, :].tolist()]\n",
    "\n",
    "#     endog_test = temps_t_test.tolist()\n",
    "#     exog_test = [np.array(seq) for seq in sequences_masked[:, -2, :].tolist()]\n",
    "# #     exog_test = [np.array(seq).mean(axis=0) for seq in sequences_test[:, -t_steps:, :].tolist()]\n",
    "    \n",
    "#     # estimate model\n",
    "#     start = time.time()\n",
    "#     arima_temp = ARIMA(endog=endog_train, exog=exog_train, order=(n_steps, 1, 0)).fit()\n",
    "#     train_time = time.time() - start\n",
    "    \n",
    "#     # get predictions (t steps)\n",
    "#     print('PREDICTING w. ARIMA, k_idx: {}'.format(k_idx))\n",
    "#     arima_preds = []\n",
    "#     for exog in exog_test:\n",
    "#         pred = arima_temp.forecast(steps=1, exog=exog)\n",
    "#         arima_preds.append(pred)\n",
    "\n",
    "#     save_path = results_path + 'arima\\\\' + model_name\n",
    "#     #arima_temp.save(save_path + '_model')\n",
    "    \n",
    "#     results = {\n",
    "#         'test_preds':arima_preds,\n",
    "#         'train_time':train_time\n",
    "#     }\n",
    "#     with open(save_path + '.pickle', 'wb') as fo:\n",
    "#         pickle.dump(results, fo)\n",
    "        \n",
    "#     ### TRAIN GBDT\n",
    "#     clear_output()\n",
    "#     print('TRAINING GBDT, k_idx: {}'.format(k_idx))\n",
    "    \n",
    "#     # get model name\n",
    "#     model_name = 'gbdt_v{}_k{}'.format(version, k_idx)\n",
    "#     gbdt = GradientBoostingRegressor(\n",
    "#         loss='squared_error',\n",
    "#         learning_rate=0.001,\n",
    "#         n_estimators=2000,\n",
    "#         max_depth=10,\n",
    "#         max_leaf_nodes=None,\n",
    "#         #subsample=0.7,\n",
    "#         verbose=1,\n",
    "# #         n_iter_no_change=10,\n",
    "# #         tol=1e-4,\n",
    "# #         validation_fraction=0.1\n",
    "#     )\n",
    "    \n",
    "#     # train GBDT\n",
    "#     start = time.time()\n",
    "#     X_train = np.hstack((np.stack(exog_train), temps_t_train))\n",
    "#     gbdt.fit(X_train, targets_train.flatten())\n",
    "#     train_time = time.time() - start\n",
    "    \n",
    "#     # create queue for preds\n",
    "#     pred_queue = deque(maxlen=t_steps)\n",
    "#     for temp in temps_t_test[:t_steps]:\n",
    "#         pred_queue.append(temp)\n",
    "    \n",
    "#     # iterate over test seqs and get preds\n",
    "#     gbdt_preds = []\n",
    "#     X_test = [np.array(seq) for seq in sequences_masked[:, -2, :].tolist()]\n",
    "#     X_test = np.hstack((np.stack(X_test), temps_t_test))\n",
    "\n",
    "#     for x in X_test:\n",
    "#         temp = np.array([pred_queue.popleft()])\n",
    "#         x[-1] = temp[0][0]\n",
    "#         temp_pred = gbdt.predict(x[np.newaxis, :])\n",
    "#         pred_queue.append(temp_pred)\n",
    "#         gbdt_preds.append(temp_pred)\n",
    "        \n",
    "#     # save model\n",
    "#     save_path = results_path + 'gbdt\\\\' + model_name\n",
    "# #     with open(save_path + '_model.pickle'.format(gbdt_name), 'wb') as fo:\n",
    "# #         pickle.dump(gbdt, fo)\n",
    "        \n",
    "#     # save model results\n",
    "#     results = {\n",
    "#         'test_preds':gbdt_preds,\n",
    "#         'train_loss':gbdt.train_score_,\n",
    "#         'train_time':train_time,\n",
    "#         'model_params':gbdt.get_params(),\n",
    "#     }\n",
    "#     with open(save_path + '.pickle', 'wb') as fo:\n",
    "#         pickle.dump(results, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
