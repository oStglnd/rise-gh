{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c35d1cc",
   "metadata": {},
   "source": [
    "# CNN/GNN/LSTM Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195db0c9",
   "metadata": {},
   "source": [
    "## Import dependencies and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77453a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf\n",
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5dee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant paths\n",
    "home_path = os.path.dirname(os.getcwd())\n",
    "data_path = home_path + '\\\\data\\\\'\n",
    "plot_path = home_path + '\\\\plotting\\\\plots\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a747b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get merged data\n",
    "data = pd.read_csv(\n",
    "    data_path + 'data_merged.csv',\n",
    "    header=[0, 1],\n",
    "    index_col=[0, 1, 2, 3]\n",
    ")\n",
    "\n",
    "# convert index.date col to datetime\n",
    "#data.index = pd.to_datetime(data.index.values)\n",
    "data.index = data.index.set_levels(\n",
    "    levels=pd.to_datetime(data.index.get_level_values(3).values),\n",
    "    level=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0f46624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X vars\n",
    "x_vars = [\n",
    "    ('pressure', 'DC_GP101'),\n",
    "    ('pressure', 'SMHI'),\n",
    "    ('flow', 'TA01_GP101_default'),\n",
    "    ('flow', 'FF01_GP101_default'),\n",
    "    ('temperatures', 'DC_GT401_GM401'),\n",
    "    ('temperatures', 'TA01_GT10X_GM10X'),\n",
    "    ('temperatures', 'DC_GT301_damped'),\n",
    "    ('temperatures', 'DC_GT301_outdoor'),\n",
    "    ('humidity', 'TA01_GT10X_GM10X'),\n",
    "    ('humidity', 'DC_GT401_GM401'),\n",
    "    ('humidity', 'SMHI'),\n",
    "    ('setpoints', 'DC_GP101_default'),\n",
    "    ('setpoints', 'TA01_GT10X_GM10X_default')\n",
    "]\n",
    "\n",
    "# filter columns to keep only x_vars\n",
    "data = data[x_vars].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be306b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs\n",
      "\n",
      "category      sensor_ID               \n",
      "pressure      DC_GP101                    0\n",
      "              SMHI                        0\n",
      "flow          TA01_GP101_default          0\n",
      "              FF01_GP101_default          0\n",
      "temperatures  DC_GT401_GM401              0\n",
      "              TA01_GT10X_GM10X            0\n",
      "              DC_GT301_damped             0\n",
      "              DC_GT301_outdoor            0\n",
      "humidity      TA01_GT10X_GM10X            0\n",
      "              DC_GT401_GM401              0\n",
      "              SMHI                        0\n",
      "setpoints     DC_GP101_default            0\n",
      "              TA01_GT10X_GM10X_default    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print number of NAs\n",
    "print('Number of NAs\\n')\n",
    "print(data.isna().sum())\n",
    "print('\\n\\n')\n",
    "\n",
    "# check for NaNs\n",
    "nadat = data.droplevel(level=0, axis=1)[[\n",
    "    'TA01_GP101_default', \n",
    "    'FF01_GP101_default',\n",
    "    'DC_GP101_default',\n",
    "    'TA01_GT10X_GM10X_default'\n",
    "]]\n",
    "\n",
    "## display NaNs across days\n",
    "#print(nadat.isna().groupby(['month', 'day']).sum())\n",
    "##print(nadat.isna().groupby('day').sum())\n",
    "\n",
    "## remove NANs\n",
    "#data = data.dropna(\n",
    "#    how='any', \n",
    "#    subset=x_vars\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee866674",
   "metadata": {},
   "source": [
    "## Process / transform variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdoors pressure in hPA...\n",
    "\n",
    "# TA02 not needed\n",
    "\n",
    "# Use temperature DIfF w.r.t. setpoint\n",
    "\n",
    "# Use rolling avg. f. humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418beff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70925b7a",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff921a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_extract(x, n_steps):\n",
    "    \"\"\"\n",
    "    Create sequences f. CNN, incl. channel dim.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    sequences = np.stack([\n",
    "        x[i:i+n_steps] for i in range(n - n_steps)\n",
    "    ])\n",
    "    \n",
    "    return sequences[..., np.newaxis]\n",
    "\n",
    "def data_split(data, var):\n",
    "    \"\"\"\n",
    "    Split and whiten data. Using training mean and s.d. also for test data.\n",
    "    \"\"\"\n",
    "    x_train = data[data.index.get_level_values(0) != 2 ][var].values\n",
    "    x_test = data[data.index.get_level_values(0) == 2][var].values\n",
    "    \n",
    "    # Whiten both sets w. training params\n",
    "    mean = np.mean(x_train)\n",
    "    std = np.std(x_train)\n",
    "    \n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    # get sequences\n",
    "    x_train = seq_extract(\n",
    "        x=x_train,\n",
    "        n_steps=120\n",
    "    )\n",
    "\n",
    "    x_test = seq_extract(\n",
    "        x=x_test,\n",
    "        n_steps=120\n",
    "    )\n",
    "    \n",
    "    return x_train, x_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902451d",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7818d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43179963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
